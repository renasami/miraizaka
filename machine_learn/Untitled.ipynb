{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab9e305a-45ca-452d-a6be-9e59c5933a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torchvision import models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "print(torch.__version__)\n",
    "net = models.vgg16(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac8db68a-2ce1-410a-818e-836816b4ed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76d9aad2-4794-4897-9cd3-5601823710cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (8): ReLU(inplace=True)\n",
      "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (11): ReLU(inplace=True)\n",
      "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (13): ReLU(inplace=True)\n",
      "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (15): ReLU(inplace=True)\n",
      "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (18): ReLU(inplace=True)\n",
      "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (20): ReLU(inplace=True)\n",
      "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (22): ReLU(inplace=True)\n",
      "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (25): ReLU(inplace=True)\n",
      "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (27): ReLU(inplace=True)\n",
      "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (29): ReLU(inplace=True)\n",
      "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=200, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.25, inplace=False)\n",
      "    (4): Linear(in_features=200, out_features=20, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#net.avgpool = Identity()\n",
    "#net.classifier[-1] = nn.Linear(512,20)\n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(1000,200),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(200),\n",
    "    nn.Dropout(0.25),\n",
    "    nn.Linear(200,20)\n",
    ")\n",
    "\n",
    "net = nn.Sequential(\n",
    "    net,\n",
    "    mlp\n",
    ")\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfc3eb76-61ad-4120-923c-8ebad3e82147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "708 304\n",
      "<torch.utils.data.dataloader.DataLoader object at 0xffff4a217d60>\n"
     ]
    }
   ],
   "source": [
    "img = ImageFolder(\n",
    "    \"./face\",\n",
    "    transform=transforms.Compose([\n",
    "      transforms.Resize(299),\n",
    "      transforms.CenterCrop(299),\n",
    "      transforms.ToTensor()]    \n",
    "))\n",
    "\n",
    "img_class = [str(n) for n in range(20)]\n",
    "\n",
    "train, test = train_test_split(img, test_size=0.3)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train,batch_size = 5 , shuffle=True)\n",
    "test_loader = DataLoader(\n",
    "    test,batch_size=5,shuffle=False)\n",
    "print(len(train),len(test))\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b0a7821-6283-4c4f-865b-8f39b3ed5b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_net(net, data_loader, device=\"cpu\"):\n",
    "    # DropoutやBatchNormを無効化\n",
    "    net.eval()\n",
    "    ys = []\n",
    "    ypreds = []\n",
    "    for x, y in data_loader:\n",
    "        # toメソッドで計算を実行するデバイスに転送する\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        # 確率が最大のクラスを予測(リスト2.14参照)\n",
    "        # ここではforward（推論）の計算だけなので自動微分に\n",
    "        # 必要な処理はoffにして余計な計算を省く\n",
    "        with torch.no_grad():\n",
    "            _, y_pred = net(x).max(1)\n",
    "        ys.append(y)\n",
    "        ypreds.append(y_pred)\n",
    "    # ミニバッチごとの予測結果などを1つにまとめる\n",
    "    ys = torch.cat(ys)\n",
    "    ypreds = torch.cat(ypreds)\n",
    "    # 予測精度を計算\n",
    "    acc = (ys == ypreds).float().sum() / len(ys)\n",
    "    return acc.item()\n",
    "\n",
    "def train_net(net, train_loader, test_loader,\n",
    "              only_fc=True,\n",
    "              optimizer_cls=optim.Adam,\n",
    "              loss_fn=nn.CrossEntropyLoss(),\n",
    "              n_iter=10, device=\"cpu\"):\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    if only_fc:\n",
    "        # 最後の線形層のパラメータのみを、\n",
    "        # optimizerに渡す\n",
    "        optimizer = optimizer_cls(net.parameters())\n",
    "    else:\n",
    "        optimizer = optimizer_cls(net.parameters())\n",
    "    for epoch in range(n_iter):\n",
    "        running_loss = 0.0\n",
    "        # ネットワークを訓練モードにする\n",
    "        net.train()\n",
    "        n = 0\n",
    "        n_acc = 0\n",
    "        # 非常に時間がかかるのでtqdmを使用してプログレスバーを出す\n",
    "        for i, (xx, yy) in tqdm.tqdm(enumerate(train_loader),\n",
    "            total=len(train_loader)):\n",
    "            xx = xx.to(device)\n",
    "            yy = yy.to(device)\n",
    "            \n",
    "            h = net(xx)\n",
    "            loss = loss_fn(h, yy)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            n += len(xx)\n",
    "            _, y_pred = h.max(1)\n",
    "            n_acc += (yy == y_pred).float().sum().item()\n",
    "        train_losses.append(running_loss / i)\n",
    "        # 訓練データの予測精度\n",
    "        train_acc.append(n_acc / n)\n",
    "        # 検証データの予測精度\n",
    "        val_acc.append(eval_net(net, test_loader, device))\n",
    "        # このepochでの結果を表示\n",
    "        print(epoch, train_losses[-1], train_acc[-1],\n",
    "              val_acc[-1], flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a983e2f-bbaa-4f7c-9e20-217a05611c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [12:23<00:00,  5.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.7733196332945047 0.10734463276836158 0.12828947603702545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [12:13<00:00,  5.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2.6058245973384127 0.13983050847457626 0.14473684132099152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [12:09<00:00,  5.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2.4510025496178485 0.2189265536723164 0.17763157188892365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [11:56<00:00,  5.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2.1786855459213257 0.3093220338983051 0.24671052396297455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [11:17<00:00,  4.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1.9352494326043637 0.3573446327683616 0.5921052694320679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [10:42<00:00,  4.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 1.7237268386157691 0.4661016949152542 0.5328947305679321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/142 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "train_net(net, train_loader, test_loader, n_iter=20, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8247e8-0b5d-4d37-be75-814b962137e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
